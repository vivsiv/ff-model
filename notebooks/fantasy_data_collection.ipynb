{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.processor import FantasyDataProcessor\n",
    "from src.scraper import ProFootballReferenceScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "Let's use the ProFootballReferenceScraper to collect NFL player and team statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping years:   0%|          | 0/2 [00:00<?, ?it/s]2025-07-01 14:29:59,519 - src.scraper - INFO - scrape_years - Scraping data from 2023\n",
      "2025-07-01 14:29:59,520 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2023_player_fantasy_stats.html\n",
      "2025-07-01 14:29:59,816 - src.scraper - INFO - scrape_html_table - Adjusted headers from 43 to 33\n",
      "2025-07-01 14:29:59,828 - src.scraper - INFO - scrape_player_fantasy_stats - Saved fantasy stats for 2023 to ../data/bronze/2023_player_fantasy_stats.csv\n",
      "2025-07-01 14:29:59,830 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2023_passing_stats.html\n",
      "2025-07-01 14:29:59,959 - src.scraper - INFO - scrape_html_table - Adjusted headers from 50 to 42\n",
      "2025-07-01 14:29:59,986 - src.scraper - INFO - scrape_player_offensive_stats - Saved passing stats for 2023 to ../data/bronze/2023_player_passing_stats.csv\n",
      "2025-07-01 14:29:59,995 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2023_rushing_stats.html\n",
      "2025-07-01 14:30:00,336 - src.scraper - INFO - scrape_html_table - Adjusted headers from 20 to 17\n",
      "2025-07-01 14:30:00,351 - src.scraper - INFO - scrape_player_offensive_stats - Saved rushing stats for 2023 to ../data/bronze/2023_player_rushing_stats.csv\n",
      "2025-07-01 14:30:00,356 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2023_receiving_stats.html\n",
      "2025-07-01 14:30:00,818 - src.scraper - INFO - scrape_html_table - Adjusted headers from 26 to 23\n",
      "2025-07-01 14:30:00,831 - src.scraper - INFO - scrape_player_offensive_stats - Saved receiving stats for 2023 to ../data/bronze/2023_player_receiving_stats.csv\n",
      "2025-07-01 14:30:00,841 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2023_team_offense.html\n",
      "/Users/viveksivakumar/Code/ff-model/notebooks/../src/scraper.py:117: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  comment_soup = BeautifulSoup(comment, 'lxml')\n",
      "2025-07-01 14:30:00,974 - src.scraper - INFO - scrape_html_table - Found table 'team_stats' inside HTML comment for year 2023\n",
      "2025-07-01 14:30:00,993 - src.scraper - INFO - scrape_html_table - Adjusted headers from 40 to 28\n",
      "2025-07-01 14:30:01,010 - src.scraper - INFO - scrape_team_offensive_stats - Saved team offense stats for 2023 to ../data/bronze/2023_team_offense.csv\n",
      "2025-07-01 14:30:01,014 - src.scraper - INFO - scrape_years - Completed scraping data from 2023\n",
      "Scraping years:  50%|█████     | 1/2 [00:01<00:01,  1.51s/it]2025-07-01 14:30:01,031 - src.scraper - INFO - scrape_years - Scraping data from 2024\n",
      "2025-07-01 14:30:01,038 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2024_player_fantasy_stats.html\n",
      "2025-07-01 14:30:01,550 - src.scraper - INFO - scrape_html_table - Adjusted headers from 43 to 33\n",
      "2025-07-01 14:30:01,555 - src.scraper - INFO - scrape_player_fantasy_stats - Saved fantasy stats for 2024 to ../data/bronze/2024_player_fantasy_stats.csv\n",
      "2025-07-01 14:30:01,558 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2024_passing_stats.html\n",
      "2025-07-01 14:30:01,672 - src.scraper - INFO - scrape_html_table - Adjusted headers from 50 to 42\n",
      "2025-07-01 14:30:01,687 - src.scraper - INFO - scrape_player_offensive_stats - Saved passing stats for 2024 to ../data/bronze/2024_player_passing_stats.csv\n",
      "2025-07-01 14:30:01,692 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2024_rushing_stats.html\n",
      "2025-07-01 14:30:02,176 - src.scraper - INFO - scrape_html_table - Adjusted headers from 20 to 17\n",
      "2025-07-01 14:30:02,209 - src.scraper - INFO - scrape_player_offensive_stats - Saved rushing stats for 2024 to ../data/bronze/2024_player_rushing_stats.csv\n",
      "2025-07-01 14:30:02,211 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2024_receiving_stats.html\n",
      "2025-07-01 14:30:02,916 - src.scraper - INFO - scrape_html_table - Adjusted headers from 26 to 23\n",
      "2025-07-01 14:30:02,948 - src.scraper - INFO - scrape_player_offensive_stats - Saved receiving stats for 2024 to ../data/bronze/2024_player_receiving_stats.csv\n",
      "2025-07-01 14:30:02,956 - src.scraper - INFO - _get_soup - Using existing html file ../data/html/2024_team_offense.html\n",
      "2025-07-01 14:30:03,156 - src.scraper - INFO - scrape_html_table - Found table 'team_stats' inside HTML comment for year 2024\n",
      "2025-07-01 14:30:03,163 - src.scraper - INFO - scrape_html_table - Adjusted headers from 40 to 28\n",
      "2025-07-01 14:30:03,172 - src.scraper - INFO - scrape_team_offensive_stats - Saved team offense stats for 2024 to ../data/bronze/2024_team_offense.csv\n",
      "2025-07-01 14:30:03,173 - src.scraper - INFO - scrape_years - Completed scraping data from 2024\n",
      "Scraping years: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "pfr = ProFootballReferenceScraper(data_dir=\"../data\")\n",
    "pfr.scrape_years(start_year=2023, end_year=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Build the silver layer from the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = FantasyDataProcessor(data_dir=\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files matching: *_player_fantasy_stats.csv: 100%|██████████| 2/2 [00:00<00:00, 152.90it/s]\n",
      "2025-07-02 15:13:57,042 - src.processor - INFO - Saved player_fantasy_stats.csv to ../data/silver/player_fantasy_stats.csv\n",
      "Processing files matching: *_player_receiving_stats.csv: 100%|██████████| 2/2 [00:00<00:00, 213.83it/s]\n",
      "2025-07-02 15:13:57,162 - src.processor - INFO - Saved player_receiving_stats.csv to ../data/silver/player_receiving_stats.csv\n",
      "Processing files matching: *_player_rushing_stats.csv: 100%|██████████| 2/2 [00:00<00:00, 242.12it/s]\n",
      "2025-07-02 15:13:57,293 - src.processor - INFO - Saved player_rushing_stats.csv to ../data/silver/player_rushing_stats.csv\n",
      "Processing files matching: *_player_passing_stats.csv: 100%|██████████| 2/2 [00:00<00:00, 259.37it/s]\n",
      "2025-07-02 15:13:57,341 - src.processor - INFO - Saved player_passing_stats.csv to ../data/silver/player_passing_stats.csv\n",
      "Processing files matching: *_team_offense.csv: 100%|██████████| 2/2 [00:00<00:00, 350.64it/s]\n",
      "2025-07-02 15:13:57,379 - src.processor - INFO - Saved team_offense.csv to ../data/silver/team_offense.csv\n"
     ]
    }
   ],
   "source": [
    "processor.build_player_fantasy_stats()\n",
    "processor.build_player_receiving_stats()\n",
    "processor.build_player_rushing_stats()\n",
    "processor.build_player_passing_stats()\n",
    "processor.build_team_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.join_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview a player stats file\n",
    "player_files = [f for f in raw_files if 'player_stats' in f]\n",
    "if player_files:\n",
    "    latest_player_file = sorted(player_files)[-1]\n",
    "    print(f\"Loading {latest_player_file}...\")\n",
    "    \n",
    "    player_data = pd.read_csv(f'../data/raw/{latest_player_file}')\n",
    "    print(f\"Shape: {player_data.shape}\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    player_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview a team stats file\n",
    "team_files = [f for f in raw_files if 'team_stats' in f]\n",
    "if team_files:\n",
    "    latest_team_file = sorted(team_files)[-1]\n",
    "    print(f\"Loading {latest_team_file}...\")\n",
    "    \n",
    "    team_data = pd.read_csv(f'../data/raw/{latest_team_file}')\n",
    "    print(f\"Shape: {team_data.shape}\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    team_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Check\n",
    "\n",
    "Let's check the quality of the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in player data\n",
    "if 'player_data' in locals():\n",
    "    print(\"Missing values in player data:\")\n",
    "    print(player_data.isnull().sum())\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"\\nData types in player data:\")\n",
    "    print(player_data.dtypes)\n",
    "    \n",
    "    # Check for duplicates\n",
    "    print(f\"\\nDuplicate rows in player data: {player_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in team data\n",
    "if 'team_data' in locals():\n",
    "    print(\"Missing values in team data:\")\n",
    "    print(team_data.isnull().sum())\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"\\nData types in team data:\")\n",
    "    print(team_data.dtypes)\n",
    "    \n",
    "    # Check for duplicates\n",
    "    print(f\"\\nDuplicate rows in team data: {team_data.duplicated().sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
