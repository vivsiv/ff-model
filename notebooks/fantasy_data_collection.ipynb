{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.processor import FantasyDataProcessor\n",
    "from src.scraper import ProFootballReferenceScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "Let's use the ProFootballReferenceScraper to collect NFL player and team statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping years:   0%|          | 0/2 [00:00<?, ?it/s]2025-07-07 22:52:49,649 - src.scraper - INFO - Scraping data from 2023\n",
      "2025-07-07 22:52:49,650 - src.scraper - INFO - Using existing html file ../data/html/2023_player_fantasy_stats.html\n",
      "2025-07-07 22:52:49,917 - src.scraper - INFO - Adjusted headers from 43 to 33\n",
      "2025-07-07 22:52:49,925 - src.scraper - INFO - Saved fantasy stats for 2023 to ../data/bronze/2023_player_fantasy_stats.csv\n",
      "2025-07-07 22:52:49,925 - src.scraper - INFO - Using existing html file ../data/html/2023_passing_stats.html\n",
      "/Users/viveksivakumar/Code/ff-model/notebooks/../src/scraper.py:117: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  comment_soup = BeautifulSoup(comment, 'lxml')\n",
      "2025-07-07 22:52:50,041 - src.scraper - ERROR - Table with id 'passing' not found on https://www.pro-football-reference.com/years/2023/passing.htm\n",
      "2025-07-07 22:52:50,042 - src.scraper - INFO - Using existing html file ../data/html/2023_rushing_stats.html\n",
      "/Users/viveksivakumar/Code/ff-model/notebooks/../src/scraper.py:117: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  comment_soup = BeautifulSoup(comment, 'lxml')\n",
      "2025-07-07 22:52:50,181 - src.scraper - ERROR - Table with id 'rushing' not found on https://www.pro-football-reference.com/years/2023/rushing.htm\n",
      "2025-07-07 22:52:50,182 - src.scraper - INFO - Using existing html file ../data/html/2023_receiving_stats.html\n",
      "/Users/viveksivakumar/Code/ff-model/notebooks/../src/scraper.py:117: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  comment_soup = BeautifulSoup(comment, 'lxml')\n",
      "2025-07-07 22:52:50,407 - src.scraper - ERROR - Table with id 'receiving' not found on https://www.pro-football-reference.com/years/2023/receiving.htm\n",
      "2025-07-07 22:52:50,408 - src.scraper - INFO - Using existing html file ../data/html/2023_team_offense.html\n",
      "/Users/viveksivakumar/Code/ff-model/notebooks/../src/scraper.py:117: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  comment_soup = BeautifulSoup(comment, 'lxml')\n",
      "2025-07-07 22:52:50,445 - src.scraper - INFO - Found table 'team_stats' inside HTML comment for year 2023\n",
      "2025-07-07 22:52:50,449 - src.scraper - INFO - Adjusted headers from 40 to 28\n",
      "2025-07-07 22:52:50,451 - src.scraper - INFO - Saved team offense stats for 2023 to ../data/bronze/2023_team_offense.csv\n",
      "2025-07-07 22:52:50,452 - src.scraper - INFO - Completed scraping data from 2023\n",
      "Scraping years:  50%|█████     | 1/2 [00:00<00:00,  1.25it/s]2025-07-07 22:52:50,453 - src.scraper - INFO - Scraping data from 2024\n",
      "2025-07-07 22:52:50,453 - src.scraper - INFO - Using existing html file ../data/html/2024_player_fantasy_stats.html\n",
      "2025-07-07 22:52:50,754 - src.scraper - INFO - Adjusted headers from 43 to 33\n",
      "2025-07-07 22:52:50,760 - src.scraper - INFO - Saved fantasy stats for 2024 to ../data/bronze/2024_player_fantasy_stats.csv\n",
      "2025-07-07 22:52:50,761 - src.scraper - INFO - Using existing html file ../data/html/2024_passing_stats.html\n",
      "2025-07-07 22:52:50,842 - src.scraper - ERROR - Table with id 'passing' not found on https://www.pro-football-reference.com/years/2024/passing.htm\n",
      "2025-07-07 22:52:50,843 - src.scraper - INFO - Using existing html file ../data/html/2024_rushing_stats.html\n",
      "/Users/viveksivakumar/Code/ff-model/notebooks/../src/scraper.py:117: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  comment_soup = BeautifulSoup(comment, 'lxml')\n",
      "2025-07-07 22:52:50,993 - src.scraper - ERROR - Table with id 'rushing' not found on https://www.pro-football-reference.com/years/2024/rushing.htm\n",
      "2025-07-07 22:52:50,994 - src.scraper - INFO - Using existing html file ../data/html/2024_receiving_stats.html\n",
      "/Users/viveksivakumar/Code/ff-model/notebooks/../src/scraper.py:117: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  comment_soup = BeautifulSoup(comment, 'lxml')\n",
      "2025-07-07 22:52:51,244 - src.scraper - ERROR - Table with id 'receiving' not found on https://www.pro-football-reference.com/years/2024/receiving.htm\n",
      "2025-07-07 22:52:51,244 - src.scraper - INFO - Using existing html file ../data/html/2024_team_offense.html\n",
      "/Users/viveksivakumar/Code/ff-model/notebooks/../src/scraper.py:117: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  comment_soup = BeautifulSoup(comment, 'lxml')\n",
      "2025-07-07 22:52:51,282 - src.scraper - INFO - Found table 'team_stats' inside HTML comment for year 2024\n",
      "2025-07-07 22:52:51,285 - src.scraper - INFO - Adjusted headers from 40 to 28\n",
      "2025-07-07 22:52:51,287 - src.scraper - INFO - Saved team offense stats for 2024 to ../data/bronze/2024_team_offense.csv\n",
      "2025-07-07 22:52:51,288 - src.scraper - INFO - Completed scraping data from 2024\n",
      "Scraping years: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "pfr = ProFootballReferenceScraper(data_dir=\"../data\")\n",
    "pfr.scrape_years(start_year=2023, end_year=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Build the silver layer from the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = FantasyDataProcessor(data_dir=\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files matching: *_player_fantasy_stats.csv: 100%|██████████| 2/2 [00:00<00:00, 200.78it/s]\n",
      "2025-07-07 22:58:25,939 - src.processor - INFO - Saved player_fantasy_stats.csv to ../data/silver/player_fantasy_stats.csv\n",
      "Processing files matching: *_player_receiving_stats.csv: 100%|██████████| 2/2 [00:00<00:00, 302.48it/s]\n",
      "2025-07-07 22:58:26,052 - src.processor - INFO - Saved player_receiving_stats.csv to ../data/silver/player_receiving_stats.csv\n",
      "Processing files matching: *_player_rushing_stats.csv: 100%|██████████| 2/2 [00:00<00:00, 461.90it/s]\n",
      "2025-07-07 22:58:26,148 - src.processor - INFO - Saved player_rushing_stats.csv to ../data/silver/player_rushing_stats.csv\n",
      "Processing files matching: *_player_passing_stats.csv: 100%|██████████| 2/2 [00:00<00:00, 446.82it/s]\n",
      "2025-07-07 22:58:26,181 - src.processor - INFO - Saved player_passing_stats.csv to ../data/silver/player_passing_stats.csv\n",
      "Processing files matching: *_team_offense.csv: 100%|██████████| 2/2 [00:00<00:00, 644.34it/s]\n",
      "2025-07-07 22:58:26,201 - src.processor - INFO - Saved team_offense.csv to ../data/silver/team_offense.csv\n"
     ]
    }
   ],
   "source": [
    "processor.build_player_fantasy_stats()\n",
    "processor.build_player_receiving_stats()\n",
    "processor.build_player_rushing_stats()\n",
    "processor.build_player_passing_stats()\n",
    "processor.build_team_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 23:00:29,148 - src.processor - INFO - Saved final_stats.csv to ../data/silver/final_stats.csv\n"
     ]
    }
   ],
   "source": [
    "processor.join_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview a player stats file\n",
    "player_files = [f for f in raw_files if 'player_stats' in f]\n",
    "if player_files:\n",
    "    latest_player_file = sorted(player_files)[-1]\n",
    "    print(f\"Loading {latest_player_file}...\")\n",
    "    \n",
    "    player_data = pd.read_csv(f'../data/raw/{latest_player_file}')\n",
    "    print(f\"Shape: {player_data.shape}\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    player_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview a team stats file\n",
    "team_files = [f for f in raw_files if 'team_stats' in f]\n",
    "if team_files:\n",
    "    latest_team_file = sorted(team_files)[-1]\n",
    "    print(f\"Loading {latest_team_file}...\")\n",
    "    \n",
    "    team_data = pd.read_csv(f'../data/raw/{latest_team_file}')\n",
    "    print(f\"Shape: {team_data.shape}\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    team_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Check\n",
    "\n",
    "Let's check the quality of the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in player data\n",
    "if 'player_data' in locals():\n",
    "    print(\"Missing values in player data:\")\n",
    "    print(player_data.isnull().sum())\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"\\nData types in player data:\")\n",
    "    print(player_data.dtypes)\n",
    "    \n",
    "    # Check for duplicates\n",
    "    print(f\"\\nDuplicate rows in player data: {player_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in team data\n",
    "if 'team_data' in locals():\n",
    "    print(\"Missing values in team data:\")\n",
    "    print(team_data.isnull().sum())\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"\\nData types in team data:\")\n",
    "    print(team_data.dtypes)\n",
    "    \n",
    "    # Check for duplicates\n",
    "    print(f\"\\nDuplicate rows in team data: {team_data.duplicated().sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
